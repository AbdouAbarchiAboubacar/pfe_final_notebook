{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import stan\n",
    "from scipy.special import expit\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import normal, randint, binomial, choice\n",
    "from numpy import percentile, concatenate, array, linspace, append\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import pickle\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809694, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>nb_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251</td>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214</td>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  correct  nb_hint\n",
       "0       72      563        0        0\n",
       "1      249      563        1        0\n",
       "2      251      563        1        0\n",
       "3      214      563        1        0\n",
       "4      155      563        0        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neededData = pd.read_csv('./final_data/neededData.csv')\n",
    "print(neededData.shape)\n",
    "neededData = neededData.drop('Unnamed: 0', 1)\n",
    "neededData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = neededData[[\"user_id\",\"item_id\",\"correct\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 1084,\n",
      " 'N': 809694,\n",
      " 'S': 574,\n",
      " 'grade': array([0, 1, 1, ..., 1, 1, 1]),\n",
      " 'item': array([563, 563, 563, ..., 482, 482, 482]),\n",
      " 'subject': array([ 72, 249, 251, ..., 395, 395, 395])}\n"
     ]
    }
   ],
   "source": [
    "train_data = {'I': len(needed['item_id'].unique()),\n",
    "              'S': len(needed['user_id'].unique()),\n",
    "              'N': len(needed),\n",
    "              'item': needed['item_id'].to_numpy(),\n",
    "              'subject': needed['user_id'].to_numpy(),\n",
    "              'grade': needed['correct'].to_numpy(),}\n",
    "pprint(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1PL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1pl_model = \"\"\"\n",
    "data {\n",
    "  // numbers of things\n",
    "  \n",
    "  int<lower=1> N;  // number of observations\n",
    "  int<lower=1> I;  // items,  number of questions  \n",
    "  int<lower=1> S;  // subjects,  number of users\n",
    "  \n",
    "  // data\n",
    "  \n",
    "  int<lower=1,upper=I> item[N];\n",
    "  int<lower=1,upper=S> subject[N];\n",
    "  int<lower=0,upper=1> grade[N];\n",
    "}\n",
    "parameters {\n",
    "  // parameters\n",
    "  \n",
    "  real ability[S];             //  alpha: ability od student\n",
    "  real  difficulty[I];          //  beta: difficulty of question\n",
    "  real delta;                   // man student ability\n",
    "  \n",
    "}\n",
    "model {\n",
    "\n",
    "  ability ~ normal(0,1);         \n",
    "  difficulty ~ normal(0,1);   \n",
    "  delta ~ normal(0.75,1);\n",
    "  \n",
    "  for(n in 1:N)\n",
    "      grade[n] ~ bernoulli_logit(ability[subject[n]] - difficulty[item[n]] + delta);\n",
    "  \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit or load saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/_1pl_model_chains-2_numsamples-10000_numwarmup-1000_num_thin-1.pkl\", \"rb\") as f: \n",
    "#     data_dict = pickle.load(f)\n",
    "# posteriori = data_dict['model']\n",
    "# binary_fit = data_dict['fit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 33.0s, done."
     ]
    }
   ],
   "source": [
    "posteriori = stan.build(_1pl_model,data=train_data,random_seed = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fit = posteriori.sample(num_chains=4, num_samples=1000,num_warmup=2000,num_thin=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation implement in stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1pl_cross_val_model = \"\"\"\n",
    "functions {\n",
    "    int[] permutation_rng(int N) {\n",
    "        int y[N];\n",
    "        for (n in 1:N)\n",
    "            y[n] = n;\n",
    "        vector[N] theta = rep_vector(1.0 / N, N);\n",
    "        for (n in 1:N){\n",
    "            int i = categorical_rng(theta);\n",
    "            int temp = y[n];\n",
    "            y[n] = y[i];\n",
    "            y[i] = temp;\n",
    "        }\n",
    "        return y;\n",
    "    }\n",
    "}\n",
    "\n",
    "data {\n",
    "  // numbers of things\n",
    "  \n",
    "  int<lower=1> N;  // number of observations\n",
    "  int<lower = 0, upper = N> N_test;\n",
    "  int<lower=1> I;  // items,  number of questions  \n",
    "  int<lower=1> S;  // subjects,  number of users\n",
    "  \n",
    "  // data\n",
    "  \n",
    "  int<lower=1,upper=I> item[N];\n",
    "  int<lower=1,upper=S> subject[N];\n",
    "  int<lower=0,upper=1> grade[N];\n",
    "}\n",
    "transformed data {\n",
    "  int N_train = N - N_test;\n",
    "  int permutation[N] = permutation_rng(N);\n",
    "  // train\n",
    "  int item_train[N_train] = item[permutation[1 : N_train]];\n",
    "  int subject_train[N_train]  = subject[permutation[1 : N_train]];\n",
    "  int grade_train[N_train]  = grade[permutation[1 : N_train]];\n",
    "  int s_train = size(subject_train);\n",
    "  int i_train = size(item_train);\n",
    "  \n",
    "  \n",
    "  // test\n",
    "  int item_test[N_test] = item[permutation[N_train + 1 : N]];\n",
    "  int subject_test[N_test] = subject[permutation[N_train + 1 : N]];\n",
    "  int grade_test[N_test] = grade[permutation[N_train + 1 : N]];\n",
    "}\n",
    "parameters {\n",
    "  // parameters\n",
    "  real ability[s_train];             //  alpha: ability od student\n",
    "  real difficulty[i_train];          //  beta: difficulty of question\n",
    "  real delta;                   // man student ability\n",
    "  \n",
    "}\n",
    "model {\n",
    "\n",
    "  ability ~ normal(0,1);         \n",
    "  difficulty ~ normal(0,1);   \n",
    "  delta ~ normal(0.75,1);\n",
    "  \n",
    "  for (n in 1:N_train) {\n",
    "      grade_train[n] ~ bernoulli_logit(ability[subject_train[n]] - difficulty[item_train[n]] + delta);\n",
    "  }\n",
    "  \n",
    "}\n",
    "generated quantities {\n",
    "  int<lower=0,upper=1> y_pred[N_test];\n",
    "  int<lower=0,upper=1> y[N_test];\n",
    "  y = grade_test;\n",
    "  \n",
    "  for (n in 1:N_test) {\n",
    "      y_pred[n] = bernoulli_logit_rng(ability[subject_test[n]] - difficulty[item_test[n]] + delta);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "# cv_posteriori = stan.build(_1pl_cross_val_model,data=binary_sim_data,random_seed = 2021)\n",
    "# cv_binary_fit = posteriori.sample(num_chains=1, num_samples=2000,num_warmup=1000,num_thin=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of chunks to partition the data into:\n",
    "n_folds = 5\n",
    "whole_dataset = pd.DataFrame({i: binary_sim_data[i] \n",
    "                              for i in ['item', 'subject', 'grade']})\n",
    "test_dataset = whole_dataset.copy()\n",
    "predictions = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(n_folds):\n",
    "    print(fold)\n",
    "    test_data = test_dataset.sample(n=int(len(whole_dataset) / n_folds))\n",
    "    training_data = whole_dataset.drop(test_data.index)\n",
    "    this_fold_data = {'I': len(whole_dataset['item'].unique()),\n",
    "                      'S': len(whole_dataset['subject'].unique()),\n",
    "                      'N': len(training_data),\n",
    "                      'item': training_data['item'].to_numpy(),\n",
    "                      'subject': training_data['subject'].to_numpy(),\n",
    "                      'grade': training_data['grade'].to_numpy(),\n",
    "                      'N_new': len(test_data),\n",
    "                      'items_new': test_data['item'].to_numpy(),\n",
    "                      'subjects_new': test_data['subject'].to_numpy()}\n",
    "    posteriori = stan.build(_1pl_model,data=this_fold_data,random_seed = 2021)\n",
    "    binary_fit = posteriori.sample(num_chains=1, num_samples=100,num_warmup=5,num_thin=1)\n",
    "    this_fold_predictions = pd.DataFrame(np.round(np.mean(binary_fit['y_pred'],axis=1)).astype(int),\n",
    "                                         index=test_data.index)\n",
    "    predict = pd.concat([predictions, this_fold_predictions],axis=0)\n",
    "    predictions = predict\n",
    "    test_dataset = test_dataset.drop(test_data.index)\n",
    "predictions.sort_index(inplace=True)\n",
    "predictions.columns = ['prediction_' + str(i) for i in predictions.columns]\n",
    "output = whole_dataset.join(predictions)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossVal validation\n",
    "# az.r2_score(output['grade'],output['prediction_0'])\n",
    "# print(f\" mse = {mean_squared_error(output['grade'],output['prediction_0'])} \\n kappa = {cohen_kappa_score(output['grade'],output['prediction_0'])} \\n auc = {roc_auc_score(output['grade'],output['prediction_0'])} \\n acc = {accuracy_score(output['grade'],output['prediction_0'])}   \")\n",
    "\n",
    "###\n",
    "# mae = (pd.DataFrame([abs(output[i] - output['grade']) \n",
    "#                      for i in output[predictions.columns]])\n",
    "#        .mean(axis=1)\n",
    "#        .mean())\n",
    "# mse = (pd.DataFrame([(output[i] - output['grade']) ** 2\n",
    "#                      for i in output[predictions.columns]])\n",
    "#        .mean(axis=1)\n",
    "#        .mean())\n",
    "# print('Mean absolute error: ' + str(mae) + '\\nMean square error: ' + str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print stanfit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binary_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fit.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize parameters distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.plot_trace(binary_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export plot trace of model parameters\n",
    "# axes = az.plot_trace(binary_fit)\n",
    "# fig = axes.ravel()[0].figure\n",
    "# fig.savefig(\"model_plot-trace.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fit to inference_data\n",
    "inf_data = az.convert_to_inference_data(binary_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic az print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.bfmi(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhat = az.rhat(inf_data)\n",
    "print(rhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.mcse(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.ess(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.r2_score(train_data['grade'],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data.sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data.prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diagnostic as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_energy(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ess(\n",
    "    idata, kind=\"evolution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_kwargs = {\"color\": \"lightsteelblue\"}\n",
    "az.plot_ess(\n",
    "    idata, kind=\"evolution\", var_names=[\"ability\"],\n",
    "    color=\"royalblue\", extra_kwargs=extra_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot trace\n",
    "param = binary_fit['ability'][0]\n",
    "param2 = binary_fit['difficulty'][0]\n",
    "# param = np.mean(fit['ability'],axis=1)  ==> for mean\n",
    "# param2 = np.mean(fit['difficulty'],axis=1) ==> for mean\n",
    "\n",
    "# Summary statistics ability\n",
    "mean = np.mean(param)\n",
    "median = np.median(param)\n",
    "cred_min, cred_max = np.percentile(param, 2.5), np.percentile(param, 97.5)\n",
    "# Summary statistics dificulty\n",
    "\n",
    "mean2 = np.mean(param2)\n",
    "median2 = np.median(param2)\n",
    "cred_min2, cred_max2 = np.percentile(param2, 2.5), np.percentile(param2, 97.5)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# Plotting ability\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(param)\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel(\"ability\")\n",
    "plt.axhline(mean, color='r', lw=2, linestyle='--')\n",
    "plt.axhline(median, color='c', lw=2, linestyle='--')\n",
    "plt.axhline(cred_min, linestyle=':', color='k', alpha=0.2)\n",
    "plt.axhline(cred_max, linestyle=':', color='k', alpha=0.2)\n",
    "plt.title(\"Trace et distribution postérieure pour la capacité de l'élève[0]\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(param, 30, density=True); sns.kdeplot(param, shade=True)\n",
    "plt.xlabel(\"ability\")\n",
    "plt.ylabel('density')\n",
    "plt.axvline(mean, color='r', lw=2, linestyle='--',label='mean')\n",
    "plt.axvline(median, color='c', lw=2, linestyle='--',label='median')\n",
    "plt.axvline(cred_min, linestyle=':', color='k', alpha=0.2, label='95% CI')\n",
    "plt.axvline(cred_max, linestyle=':', color='k', alpha=0.2)\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "# Plotting dificulty\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(param2)\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel(\"ability\")\n",
    "plt.axhline(mean2, color='r', lw=2, linestyle='--')\n",
    "plt.axhline(median2, color='c', lw=2, linestyle='--')\n",
    "plt.axhline(cred_min2, linestyle=':', color='k', alpha=0.2)\n",
    "plt.axhline(cred_max2, linestyle=':', color='k', alpha=0.2)\n",
    "plt.title(\"Trace et distribution postérieure pour la difficulté de l'item[0]\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(param2, 30, density=True); sns.kdeplot(param2, shade=True)\n",
    "plt.xlabel(\"difficulty\")\n",
    "plt.ylabel('density')\n",
    "plt.axvline(mean2, color='r', lw=2, linestyle='--',label='mean')\n",
    "plt.axvline(median2, color='c', lw=2, linestyle='--',label='median')\n",
    "plt.axvline(cred_min2, linestyle=':', color='k', alpha=0.2, label='95% CI')\n",
    "plt.axvline(cred_max2, linestyle=':', color='k', alpha=0.2)\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "# save trace plot\n",
    "plt.savefig(\"./final_data/params_posterior_distribution.png\",bbox_inches='tight', pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ability = np.mean(binary_fit['ability'],axis=1)\n",
    "difficulty = np.mean(binary_fit['difficulty'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [] #809660\n",
    "for i in range(0,10000):\n",
    "    diff = binary_sim_data['item'][i]\n",
    "    abilt = binary_sim_data['subject'][i]\n",
    "    p = np.exp(ability[abilt - 1 ] - difficulty[diff - 1])/(1+np.exp(ability[abilt - 1] - difficulty[diff - 1]))\n",
    "    y_pred.append(p)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" mse = {mean_squared_error(binary_sim_data['grade'],y_pred)} \\n kappa = {cohen_kappa_score(binary_sim_data['grade'],y_pred)} \\n auc = {roc_auc_score(binary_sim_data['grade'],y_pred)} \\n acc = {accuracy_score(binary_sim_data['grade'],y_pred)}   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./final_data/_1pl_model_chains-2_numsamples-10000_numwarmup-1000_num_thin-1.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : posteriori, 'fit' : binary_fit}, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2PL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2pl_model = \"\"\"\n",
    "data {\n",
    "  // numbers of things\n",
    "  \n",
    "  int<lower=1> N;  // number of observations\n",
    "  int<lower=1> I;  // items,  number of questions  \n",
    "  int<lower=1> S;  // subjects,  number of users\n",
    "  \n",
    "  // data\n",
    "  \n",
    "  int<lower=1,upper=I> item[N];\n",
    "  int<lower=1,upper=S> subject[N];\n",
    "  int<lower=0,upper=1> grade[N];\n",
    "}\n",
    "parameters {\n",
    "  // parameters\n",
    "  \n",
    "  vector[S] ability;             //  alpha ability od student\n",
    "  vector[I] difficulty;          //  beta difficulty of question\n",
    "  vector<lower=0>[I] discrimination;      // discrimination of question\n",
    "  real mu_difficulty;\n",
    "}\n",
    "model {\n",
    "  ability ~ std_normal();         \n",
    "  difficulty ~ std_normal();   \n",
    "  discrimination ~ lognormal(0,1);\n",
    "  mu_difficulty ~ cauchy(0,5);\n",
    "  \n",
    "  grade ~ bernoulli_logit(discrimination[item] .* (ability[subject] - (difficulty[item] + mu_difficulty)));\n",
    "  \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriori2 = stan.build(_2pl_model,data=binary_sim_data,random_seed = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fit2 = posteriori2.sample(num_chains=1, num_samples=200,num_warmup=100,num_thin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(binary_fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ability2 = np.mean(binary_fit2['ability'],axis=1)\n",
    "difficulty2 = np.mean(binary_fit2['difficulty'],axis=1)\n",
    "discrimination2 = np.mean(binary_fit2['discrimination'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = []\n",
    "for i in range(0,10000):\n",
    "    diff = binary_sim_data['item'][i]\n",
    "    abilt = binary_sim_data['subject'][i]\n",
    "    p = np.exp(discrimination2[diff-1]*(ability2[abilt - 1 ] - difficulty2[diff - 1]))/(1+np.exp(discrimination2[diff-1]*(ability2[abilt - 1] - difficulty2[diff - 1])))\n",
    "    y_pred2.append(p)\n",
    "y_pred2 = np.round(y_pred2).astype(int)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" mse = {mean_squared_error(binary_sim_data['grade'],y_pred2)} \\n kappa = {cohen_kappa_score(binary_sim_data['grade'],y_pred2)} \\n auc = {roc_auc_score(binary_sim_data['grade'],y_pred2)} \\n acc = {accuracy_score(binary_sim_data['grade'],y_pred2)}   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./final_data/_2pl_model_chains-2_numsamples-10000_numwarmup-1000_num_thin-1.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : posteriori2, 'fit' : binary_fi2t}, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3PL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3pl_model = \"\"\"\n",
    "data {\n",
    "  // numbers of things\n",
    "  \n",
    "  int<lower=1> N;  // number of observations\n",
    "  int<lower=1> I;  // items,  number of questions  \n",
    "  int<lower=1> S;  // subjects,  number of users\n",
    "  \n",
    "  // data\n",
    "  \n",
    "  int<lower=1,upper=I> item[N];\n",
    "  int<lower=1,upper=S> subject[N];\n",
    "  int<lower=0,upper=1> grade[N];\n",
    "}\n",
    "parameters {\n",
    "  // parameters\n",
    "  \n",
    "  vector[S] ability;             //  alpha ability od student\n",
    "  vector[I] difficulty;          //  beta difficulty of question\n",
    "  vector<lower=0>[I] discrimination;      // discrimination of question\n",
    "  vector<lower=0,upper=1>[I] guessing;\n",
    "  real mu_difficulty;\n",
    "}\n",
    "model {\n",
    "  ability ~ std_normal();         \n",
    "  difficulty ~ std_normal();   \n",
    "  discrimination ~ lognormal(0,1);\n",
    "  guessing ~ beta(5,17);\n",
    "  mu_difficulty ~ cauchy(0,5);\n",
    "  \n",
    "\n",
    "  grade ~ bernoulli_logit(guessing[item] + ((1-guessing[item]).*(inv_logit(discrimination[item] .* (ability[subject] - (difficulty[item] + mu_difficulty))))));\n",
    "  \n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriori3 = stan.build(_3pl_model,data=binary_sim_data,random_seed = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fit3 = posteriori3.sample(num_chains=1, num_samples=2000,num_warmup=1000,num_thin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(binary_fit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ability3 = np.mean(binary_fit3['ability'],axis=1)\n",
    "difficulty3 = np.mean(binary_fit3['difficulty'],axis=1)\n",
    "discrimination3 = np.mean(binary_fit3['discrimination'],axis=1)\n",
    "guessing3 = np.mean(binary_fit3['guessing'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = []\n",
    "for i in range(0,10000):\n",
    "    diff = binary_sim_data['item'][i]\n",
    "    abilt = binary_sim_data['subject'][i]\n",
    "    p = guessing3[diff-1] + ((1-guessing3[diff-1]) / (1 + np.exp(-discrimination3[diff-1]*(ability3[abilt - 1] - difficulty3[diff - 1]))))\n",
    "    y_pred3.append(p)\n",
    "y_pred3 = np.round(y_pred3).astype(int)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" mse = {mean_squared_error(binary_sim_data['grade'],y_pred3)} \\n kappa = {cohen_kappa_score(binary_sim_data['grade'],y_pred3)} \\n auc = {roc_auc_score(binary_sim_data['grade'],y_pred3)} \\n acc = {accuracy_score(binary_sim_data['grade'],y_pred3)}   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posteriori' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bd2fd9b1a167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./final_data/_2pl_model_chains-2_numsamples-10000_numwarmup-1000_num_thin-1.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mposteriori\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbinary_fit\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'posteriori' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"./final_data/_3pl_model_chains-2_numsamples-10000_numwarmup-1000_num_thin-1.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : posteriori3, 'fit' : binary_fit3}, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of all Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(train_data['grade'],y_pred)\n",
    "auc = metrics.roc_auc_score(train_data['grade'],y_pred)\n",
    "plt.plot(fpr,tpr,label=\"1pl model 10000 itr, auc=\"+str(auc))\n",
    "\n",
    "# pred = np.random.rand(1000)\n",
    "# label = np.random.randint(2, size=1000)\n",
    "# fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "# auc = metrics.roc_auc_score(label, pred)\n",
    "# plt.plot(fpr,tpr,label=\"data 2, auc=\"+str(auc))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
